{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f96d79a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit, current_timestamp, expr, cast\n",
    "from delta.tables import DeltaTable\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "226d04e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ntbk_logger import get_notebook_logger\n",
    "\n",
    "logger = get_notebook_logger(logfile=\"logs/scd.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca66e202",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"scd\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9eb02a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = [\n",
    "    {\"id\": 9,  \"name\": \"Ivy\", \"age\": 30, \"department\": \"Marketing\", \"salary\": 66000},\n",
    "    {\"id\": 10, \"name\": \"Jack\", \"age\": 38, \"department\": \"IT\", \"salary\": 50000},\n",
    "    {\"id\": 11, \"name\": \"Karen\", \"age\": 27, \"department\": \"HR\", \"salary\": 51000},\n",
    "    {\"id\": 12, \"name\": \"Leo\", \"age\": 41, \"department\": \"Engineering\", \"salary\": 99000},\n",
    "    {\"id\": 13, \"name\": \"Maya\", \"age\": 34, \"department\": \"Sales\", \"salary\": 61000},\n",
    "    {\"id\": 14, \"name\": \"Nina\", \"age\": 29, \"department\": \"Sales\", \"salary\": 54000},\n",
    "    {\"id\": 15, \"name\": \"Oscar\", \"age\": 32, \"department\": \"HR\", \"salary\": 54000},\n",
    "    {\"id\": 16, \"name\": \"Paul\", \"age\": 36, \"department\": \"IT\", \"salary\": 87000},\n",
    "    {\"id\": 17, \"name\": \"Queenie\", \"age\": 25, \"department\": \"Marketing\", \"salary\": 23445},\n",
    "    {\"id\": 18, \"name\": \"Raj\", \"age\": 39, \"department\": \"Sales\", \"salary\": 53000},\n",
    "    {\"id\": 19, \"name\": \"Sara\", \"age\": 28, \"department\": \"HR\", \"salary\": 50000},\n",
    "    {\"id\": 20, \"name\": \"Tom\", \"age\": 45, \"department\": \"Engineering\", \"salary\": 223344}\n",
    "]\n",
    "\n",
    "\n",
    "new_data = spark.createDataFrame(new_data)\n",
    "# FAR_FUTURE_DATE = \"9999-12-31\"\n",
    "\n",
    "# incoming_scd2_df = new_data.withColumn(\"start_time\", current_timestamp()) \\\n",
    "#                               .withColumn(\"end_time\", lit(FAR_FUTURE_DATE).cast(\"timestamp\")) \\\n",
    "#                               .withColumn(\"cur_status\", lit(\"active\"))\n",
    "\n",
    "# incoming_scd2_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0066dc81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-06 17:14:07,950 - notebook_logger - DEBUG - ------ Changes found. Proceeding with SCD2 merge.\n",
      "2025-10-06 17:14:14,915 - notebook_logger - INFO - Changes detected for IDs: [9, 10, 11, 12, 13, 14, 15, 17, 16, 18, 19, 20]\n",
      "2025-10-06 17:14:26,581 - notebook_logger - DEBUG - ------ Expired old records and inserted new records\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    delta_table_path = \"data/employee\"\n",
    "\n",
    "    # Set new records to be active\n",
    "    FAR_FUTURE_DATE = \"9999-12-31\"\n",
    "    incoming_scd2_df = new_data.withColumn(\"start_time\", current_timestamp()) \\\n",
    "                                  .withColumn(\"end_time\", lit(FAR_FUTURE_DATE).cast(\"timestamp\")) \\\n",
    "                                  .withColumn(\"cur_status\", lit(\"active\"))\n",
    "\n",
    "    if DeltaTable.isDeltaTable(spark, delta_table_path):\n",
    "        delta_table = DeltaTable.forPath(spark, delta_table_path)\n",
    "        existing_df = delta_table.toDF().filter(\"cur_status = 'active'\")\n",
    "\n",
    "        # Check for changed records for salary/department or new ids\n",
    "        compare_df = incoming_scd2_df.alias(\"incoming\").join(\n",
    "            existing_df.alias(\"existing\"), on=\"id\", how=\"left_outer\"\n",
    "        ).filter(\n",
    "            (col(\"existing.id\").isNull()) | \n",
    "            (col(\"incoming.salary\") != col(\"existing.salary\")) |\n",
    "            (col(\"incoming.department\") != col(\"existing.department\"))\n",
    "        ).select(\"incoming.*\")  # Only changed or new records\n",
    "\n",
    "\n",
    "        # If any changes, run SCD2 merge\n",
    "        if compare_df.count():\n",
    "            logger.debug(\"------ Changes found. Proceeding with SCD2 merge.\")\n",
    "            changed_ids = [row[\"id\"] for row in compare_df.select(\"id\").distinct().collect()]\n",
    "            logger.info(f\"Changes detected for IDs: {changed_ids}\")\n",
    "\n",
    "            # Expire old records  (set to 'inactive')\n",
    "            # Here, target = existing records and source = new/changed records\n",
    "            delta_table.alias(\"target\").merge(\n",
    "                compare_df.alias(\"source\"),\n",
    "                \"target.id = source.id AND target.cur_status = 'active'\"\n",
    "            ).whenMatchedUpdate(condition=\"\"\"\n",
    "                    target.department != source.department OR \n",
    "                    target.salary != source.salary\n",
    "                \"\"\", set={\n",
    "                    \"end_time\": \"current_timestamp()\",\n",
    "                    \"cur_status\": \"'inactive'\"\n",
    "                }\n",
    "            ).whenNotMatchedInsertAll().execute()\n",
    "            logger.debug(\"------ Expired old records and inserted new records\")\n",
    "        else:\n",
    "            logger.debug(\"------ No changes detected. Skipping merge.\")\n",
    "    else:\n",
    "        # First-time write if no existing table found \n",
    "        incoming_scd2_df.write.format(\"delta\").mode(\"overwrite\").save(delta_table_path)\n",
    "        logger.debug(\"---- Existing table not found. Created and written new table.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\" Exception in SCD2 merge: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c45829d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+---+-------+------+--------------------+--------------------+----------+\n",
      "|age| department| id|   name|salary|          start_time|            end_time|cur_status|\n",
      "+---+-----------+---+-------+------+--------------------+--------------------+----------+\n",
      "| 30|  Marketing|  9|    Ivy| 58000|2025-10-06 17:13:...|2025-10-06 17:14:...|  inactive|\n",
      "| 38|      Sales| 10|   Jack| 49000|2025-10-06 17:13:...|2025-10-06 17:14:...|  inactive|\n",
      "| 27|         HR| 11|  Karen| 51000|2025-10-06 17:14:...| 9999-12-31 00:00:00|    active|\n",
      "| 41|Engineering| 12|    Leo| 99000|2025-10-06 17:14:...| 9999-12-31 00:00:00|    active|\n",
      "| 34|      Sales| 13|   Maya| 61000|2025-10-06 17:14:...| 9999-12-31 00:00:00|    active|\n",
      "| 29|      Sales| 14|   Nina| 54000|2025-10-06 17:14:...| 9999-12-31 00:00:00|    active|\n",
      "| 32|         HR| 15|  Oscar| 54000|2025-10-06 17:14:...| 9999-12-31 00:00:00|    active|\n",
      "| 36|         IT| 16|   Paul| 87000|2025-10-06 17:14:...| 9999-12-31 00:00:00|    active|\n",
      "| 25|  Marketing| 17|Queenie| 23445|2025-10-06 17:14:...| 9999-12-31 00:00:00|    active|\n",
      "| 39|      Sales| 18|    Raj| 53000|2025-10-06 17:14:...| 9999-12-31 00:00:00|    active|\n",
      "| 28|         HR| 19|   Sara| 50000|2025-10-06 17:14:...| 9999-12-31 00:00:00|    active|\n",
      "| 45|Engineering| 20|    Tom|223344|2025-10-06 17:14:...| 9999-12-31 00:00:00|    active|\n",
      "| 42|Engineering|  4|  David| 95000|2025-10-06 17:13:...|2029-10-06 17:13:...|    active|\n",
      "| 31|         HR|  5|    Eva| 52000|2025-10-06 17:13:...|2029-10-06 17:13:...|    active|\n",
      "| 40|Engineering|  8|  Henry| 91000|2025-10-06 17:13:...|2029-10-06 17:13:...|    active|\n",
      "| 35|Engineering|  2|    Bob| 80000|2025-10-06 17:13:...|2029-10-06 17:13:...|    active|\n",
      "| 36|  Marketing|  6|  Frank| 60000|2025-10-06 17:13:...|2029-10-06 17:13:...|    active|\n",
      "| 28|      Sales|  3|Charlie| 45000|2025-10-06 17:13:...|2029-10-06 17:13:...|    active|\n",
      "| 26|      Sales|  7|  Grace| 47000|2025-10-06 17:13:...|2029-10-06 17:13:...|    active|\n",
      "| 29|         HR|  1|  Alice| 50000|2025-10-06 17:13:...|2029-10-06 17:13:...|    active|\n",
      "+---+-----------+---+-------+------+--------------------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"delta\").load(\"data/employee\")\n",
    "\n",
    "df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
